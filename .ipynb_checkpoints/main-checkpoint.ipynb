{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string, os, random\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nN = number of data points (files) |{x^(i), y^(i)}i=1->N|\\nx^(i)=[x_1^(i),...] a bag of characters\\nM_i = number of characters in x_i\\nS = set of all character types (a,b,c...)\\nK_S = |S|\\nL = set of data labels (e,s,j)\\nK_L = |L|\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "N = number of data points (files) |{x^(i), y^(i)}i=1->N|\n",
    "x^(i)=[x_1^(i),...] a bag of characters\n",
    "M_i = number of characters in x_i\n",
    "S = set of all character types (a,b,c...)\n",
    "K_S = |S|\n",
    "L = set of data labels (e,s,j)\n",
    "K_L = |L|\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name is the name of the file eg 'e0'\n",
    "# good_chars is a string of accepted characters\n",
    "# returns list of good chars in the file\n",
    "def read_file(name, good_chars=string.ascii_lowercase+\" \"):\n",
    "    # init character list\n",
    "    char_list = []\n",
    "    # open file\n",
    "    with open(f\"languageID/{name}\") as f:\n",
    "        # look at each file\n",
    "        for char in f.read():\n",
    "            # check if the character is approved, if so append it\n",
    "            if char in good_chars:\n",
    "                char_list.append(char)\n",
    "    return char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is a list\n",
    "# target is a string\n",
    "def prior(data, target, alpha, Kl=3):\n",
    "    num = alpha\n",
    "    for item in data:\n",
    "        if item == target:\n",
    "            num += 1\n",
    "    return num / (len(data) + (Kl * alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files x0.txt-x9.txt for x = e,s,j\n",
    "train_data = []\n",
    "for name in os.listdir(\"languageID\"):\n",
    "    if int(name[1:-4]) <= 9:\n",
    "        train_data.append((name, read_file(name)))\n",
    "p1_list = [tup[0][0] for tup in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 0.3333333333333333\n",
      "j: 0.3333333333333333\n",
      "s: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "prior_e = prior(p1_list, \"e\", alpha=0.5)\n",
    "print(\"e:\", prior_e)\n",
    "prior_j = prior(p1_list, \"j\", alpha=0.5)\n",
    "print(\"j:\", prior_j)\n",
    "prior_s = prior(p1_list, \"s\", alpha=0.5)\n",
    "print(\"s:\", prior_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# string of good characters\n",
    "big_string = string.ascii_lowercase+\" \"\n",
    "# dict[letter]->number i.e. a->0, b->1, ...\n",
    "let_to_num = {}\n",
    "for i in range(27):\n",
    "    letter = big_string[i]\n",
    "    let_to_num[letter] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_prob(data, y_targ, alpha=0.5):\n",
    "    # init thetas\n",
    "    theta_nums = np.zeros(27) + alpha\n",
    "    theta_dens = np.zeros(27)\n",
    "    # init S\n",
    "    S = []\n",
    "    # loops through [(e0.txt, [a, b, ...]), (e1.txt, [...]), ...]\n",
    "    for tup in data:\n",
    "        # tup[0] is the file name\n",
    "        # tup[1] is the list of chars\n",
    "        # if the file is the target file\n",
    "        if tup[0][0] == y_targ:\n",
    "            # update S\n",
    "            S = list(set(S + tup[1]))\n",
    "            # loop through characters in the file\n",
    "            for char in tup[1]:\n",
    "                # get idx\n",
    "                idx = let_to_num[char]\n",
    "                # update params\n",
    "                theta_nums[idx] += 1\n",
    "            theta_dens += len(tup[1])\n",
    "    return theta_nums / (theta_dens + (len(S)*alpha))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06016851, 0.01113497, 0.02151   , 0.02197258, 0.10536924,\n",
       "       0.01893276, 0.01747894, 0.04721626, 0.05541054, 0.00142078,\n",
       "       0.00373369, 0.02897737, 0.02051875, 0.05792169, 0.0644639 ,\n",
       "       0.01675202, 0.0005617 , 0.05382455, 0.06618206, 0.08012556,\n",
       "       0.02666446, 0.00928465, 0.01549645, 0.00115645, 0.01384437,\n",
       "       0.00062779, 0.17924996])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_e = cond_prob(train_data, \"e\")\n",
    "theta_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.31770215e-01, 1.08672863e-02, 5.48605773e-03, 1.72269201e-02,\n",
       "       6.02068628e-02, 3.87867776e-03, 1.40121602e-02, 3.17632259e-02,\n",
       "       9.70368300e-02, 2.34118387e-03, 5.74114194e-02, 1.43266476e-03,\n",
       "       3.98001258e-02, 5.67125585e-02, 9.11663988e-02, 8.73576071e-04,\n",
       "       1.04829129e-04, 4.28052275e-02, 4.21762527e-02, 5.69921029e-02,\n",
       "       7.06198896e-02, 2.44601300e-04, 1.97428192e-02, 3.49430428e-05,\n",
       "       1.41519324e-02, 7.72241247e-03, 1.23453770e-01])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_j = cond_prob(train_data, \"j\")\n",
    "theta_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.04560451e-01, 8.23286362e-03, 3.75258241e-02, 3.97459221e-02,\n",
       "       1.13810860e-01, 8.60287996e-03, 7.18448398e-03, 4.53270019e-03,\n",
       "       4.98597021e-02, 6.62945947e-03, 2.77512257e-04, 5.29431717e-02,\n",
       "       2.58086399e-02, 5.41765595e-02, 7.24923684e-02, 2.42669051e-02,\n",
       "       7.67783910e-03, 5.92951189e-02, 6.57704049e-02, 3.56140730e-02,\n",
       "       3.37023219e-02, 5.88942678e-03, 9.25040856e-05, 2.49761031e-03,\n",
       "       7.86284728e-03, 2.68261848e-03, 1.68264932e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_s = cond_prob(train_data, \"s\")\n",
    "theta_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name is the name of the file \"e10.txt\"\n",
    "# returns frequency list \n",
    "def get_theta(name):\n",
    "    theta = np.zeros(27)\n",
    "    for char in read_file(name):\n",
    "        theta[let_to_num[char]] += 1\n",
    "    return theta / sum(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0590991 , 0.01153153, 0.0190991 , 0.02054054, 0.11207207,\n",
       "       0.01981982, 0.01837838, 0.05045045, 0.05045045, 0.00108108,\n",
       "       0.00216216, 0.03063063, 0.02306306, 0.05009009, 0.06558559,\n",
       "       0.0190991 , 0.00108108, 0.05081081, 0.06702703, 0.08108108,\n",
       "       0.02342342, 0.01117117, 0.01693694, 0.00144144, 0.01369369,\n",
       "       0.00072072, 0.17945946])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_e10 = get_theta(\"e10.txt\")\n",
    "x_e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_hat(x_vec, theta_vec):\n",
    "    tot = 0\n",
    "    for i in range(len(x_vec)):\n",
    "        tot += x_vec[i] * np.log(theta_vec[i])\n",
    "    return np.exp(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05925545365454994"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like_e = p_hat(x_e10, theta_e)\n",
    "like_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.042390040304332556"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like_j = p_hat(x_e10, theta_j)\n",
    "like_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047298683887854596"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "like_s = p_hat(x_e10, theta_s)\n",
    "like_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e: 0.01975181788484998\n",
      "j: 0.014130013434777518\n",
      "s: 0.015766227962618198\n",
      "=> e\n"
     ]
    }
   ],
   "source": [
    "# q6\n",
    "print(\"e:\", prior_e * like_e)\n",
    "print(\"j:\", prior_j * like_j)\n",
    "print(\"s:\", prior_s * like_s)\n",
    "print(\"=> e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get files x10.txt-x19.txt for x = e,s,j\n",
    "test_list = []\n",
    "for name in os.listdir(\"languageID\"):\n",
    "    # avoid scrambled file\n",
    "    if len(name) < 8:\n",
    "        if int(name[1:-4]) > 9:\n",
    "            test_list.append((name, read_file(name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>English (true)</th>\n",
       "      <th>Spanish (true)</th>\n",
       "      <th>Japanese (true)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>English (pred)</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Spanish (pred)</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Japanese (pred)</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 English (true)  Spanish (true)  Japanese (true)\n",
       "English (pred)               10               0                0\n",
       "Spanish (pred)                0              10                0\n",
       "Japanese (pred)               0               0               10"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init a confusion matrix as a df\n",
    "conf_dict = {}\n",
    "langs = [\"English\", \"Spanish\", \"Japanese\"]\n",
    "for real_lang in langs:\n",
    "    conf_dict[real_lang + \" (true)\"] = {}\n",
    "    for pred_lang in langs:\n",
    "        conf_dict[real_lang + \" (true)\"][pred_lang + \" (pred)\"] = 0\n",
    "conf_df = pd.DataFrame(conf_dict)\n",
    "\n",
    "# make prior val and theta lists\n",
    "lang_list = ['e', 's', 'j']\n",
    "pri_dict = {}\n",
    "theta_dict = {}\n",
    "for lang in lang_list:\n",
    "    pri_dict[lang] = prior(test_list, lang, alpha=0.5)\n",
    "    theta_dict[lang] = cond_prob(test_list, lang)\n",
    "\n",
    "# loop through data, calc x and make pred\n",
    "for tup in test_list:\n",
    "    # get the x vector\n",
    "    x_vec = get_theta(tup[0])\n",
    "    \n",
    "    # find the likelihoods\n",
    "    like_e = p_hat(x_vec, theta_dict['e']) * pri_dict['e']\n",
    "    like_s = p_hat(x_vec, theta_dict['s']) * pri_dict['s']\n",
    "    like_j = p_hat(x_vec, theta_dict['j']) * pri_dict['j']\n",
    "    \n",
    "    # see which likelihood is the greatest\n",
    "    if like_e >= like_s and like_e >= like_j:\n",
    "        pred = \"English (pred)\"\n",
    "    if like_s > like_e and like_s >= like_j:\n",
    "        pred = \"Spanish (pred)\"\n",
    "    if like_j > like_s and like_j >= like_e:\n",
    "        pred = \"Japanese (pred)\"\n",
    "    \n",
    "    # find the true label\n",
    "    lab = tup[0][0]\n",
    "    if lab == 'e':\n",
    "        true = \"English (true)\"\n",
    "    if lab == 's':\n",
    "        true = \"Spanish (true)\"\n",
    "    if lab == 'j':\n",
    "        true = \"Japanese (true)\"\n",
    "    \n",
    "    # update the confusion matrix\n",
    "    conf_df[true][pred] += 1\n",
    "\n",
    "# view the confusion matrix\n",
    "conf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a file\n",
    "scram = read_file(\"s15.txt\")\n",
    "# shuffle it\n",
    "random.shuffle(scram)\n",
    "# write the shuffled file\n",
    "scram_string = \"\".join(scram)\n",
    "with open(\"languageID\\s15SCRAM.txt\", \"w\") as f:\n",
    "    f.write(scram_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spanish (pred)'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the x vector\n",
    "x_vec = get_theta(\"s15SCRAM.txt\")\n",
    "\n",
    "# find the likelihoods\n",
    "like_e = p_hat(x_vec, theta_dict['e']) * pri_dict['e']\n",
    "like_s = p_hat(x_vec, theta_dict['s']) * pri_dict['s']\n",
    "like_j = p_hat(x_vec, theta_dict['j']) * pri_dict['j']\n",
    "\n",
    "# see which likelihood is the greatest\n",
    "if like_e >= like_s and like_e >= like_j:\n",
    "    pred = \"English (pred)\"\n",
    "if like_s > like_e and like_s >= like_j:\n",
    "    pred = \"Spanish (pred)\"\n",
    "if like_j > like_s and like_j >= like_e:\n",
    "    pred = \"Japanese (pred)\"\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
